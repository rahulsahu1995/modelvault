# ğŸš€ MiniVault API â€“ Offline Prompt/Response System

This project simulates a core feature of **ModelVaultâ€™s product**: receiving a prompt and returning a generated response â€” all offline using a **locally hosted LLM (Falcon RW 1B)**.

---

## ğŸ› ï¸ Built With

- âš¡ **FastAPI** backend serving Falcon RW 1B
- ğŸ” **Node.js proxy server** (folder: `minivault-api/`)
- ğŸ **Python CLI** for local testing
- ğŸ“ **JSONL logging** in both backend and proxy layers

---

## ğŸ“ Project Structure

modelvault/
â”œâ”€â”€ python-code/
â”‚ â”œâ”€â”€ server.py # FastAPI backend (LLM)
â”‚ â”œâ”€â”€ cli.py # Python CLI for prompt testing
â”‚ â”œâ”€â”€ logs/
â”‚ â”‚ â””â”€â”€ log.jsonl # Backend logs
â”‚ â””â”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ minivault-api/
â”‚ â”œâ”€â”€ app.js # Node.js proxy server
â”‚ â”œâ”€â”€ logs/
â”‚ â”‚ â””â”€â”€ log.jsonl # Proxy server logs
â”‚ â””â”€â”€ package.json # Node dependencies
â””----modelvault-testcases.postman_collection.json   #postman collection
|â”€â”€ README.md # This documentation

---

## ğŸ§° Setup Instructions

### ğŸ“¦ 1. Clone the Repository


```bash

git clone <your-repo-url>
cd modelvault


ğŸ§  2. Python Backend (FastAPI)

âœ… Setup Environment

cd python-code
python -m venv .venv
# Activate the environment:
# On Windows:
.venv\Scripts\activate
# On macOS/Linux:
source .venv/bin/activate


pip install -r requirements.txt
â–¶ï¸ Run the FastAPI Server


uvicorn server:app --host 127.0.0.1 --port 8080
âš ï¸ First run will download Falcon RW 1B (~5.3GB) and cache it locally.



ğŸŒ 3. Node.js Proxy Server (minivault-api)


cd ../minivault-api
npm install
node app.js
Runs on: http://localhost:3000

Proxies to FastAPI backend on port 8080
Logs stored in: minivault-api/logs/log.jsonl


ğŸ§ª 4. Test Using Python CLI

cd ../python-code
python cli.py --prompt "Tell me a joke."
python cli.py --prompt "What is artificial intelligence?" --stream
ğŸŒ API Endpoints
ğŸ”¹ POST /generate
URL: http://localhost:3000/generate


Request:

json
{
  "prompt": "What is the capital of France?"
}
Response:

json
{
  "response": "The capital of France is Paris."
}


ğŸ”¸ POST /generate-stream


URL: http://localhost:3000/generate-stream

Behavior: Streams response character-by-character (or token-by-token) in plain text.

ğŸ§¾ Logging
All interactions are stored as JSON lines.

âœ”ï¸ Backend log: python-code/logs/log.jsonl
âœ”ï¸ Proxy log: minivault-api/logs/log.jsonl


Example:
json
{
  "timestamp": "2025-07-11T10:34:02.912Z",
  "prompt": "Tell me a joke.",
  "response": "Why did the chicken cross the road?"
}

ğŸ§  Model Details

Property	Description
Model	tiiuae/falcon-rw-1b
Size	~5.3GB
Runs Offline	âœ… Yes (after first download)
Framework	Hugging Face Transformers
Features	Text generation, token streaming



ğŸ§ª Postman Collection (Optional Testing Tool)
You can test this API using the included Postman collection:

Collection Name: minivault-testcases

Endpoints Included:

POST /generate

POST /generate-stream


âœ… How to Use:

Open Postman

Import the collection (minivault-testcases.json)

Set the prompt in the body (raw JSON)

Click Send and watch responses appear

ğŸ” For streaming responses,run this command on server side "python cli.py --prompt "What is the capital of France?" --stream" this will give streaming responses. 


